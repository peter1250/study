{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51baa613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72111bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'data_path' : 'train',\n",
    "    'batch' : 16,\n",
    "    'epoch' : 100,\n",
    "    'model' : 'efficientnet-b5',\n",
    "    'num_classes' : 88,\n",
    "    'img_size' : 456,\n",
    "    'random_seed' : 555\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25fc8c",
   "metadata": {},
   "source": [
    "# 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b039d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_df_aug.csv')\n",
    "\n",
    "label = df['label']\n",
    "le  = LabelEncoder().fit(label)\n",
    "\n",
    "label_ec = le.transform(label)\n",
    "\n",
    "encdf = pd.DataFrame(label_ec,columns = ['encode'])\n",
    "data = pd.concat([df['file_name'],encdf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2a7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def get_train_data(data_dir):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    # get image path\n",
    "    img_path_list.extend(glob(os.path.join(data_dir, '*.png')))\n",
    "    img_path_list.sort(key=lambda x:int(x.split('\\\\')[-1].split('.')[0]))\n",
    "    label_list.extend(data['encode'])\n",
    "                \n",
    "    return img_path_list, label_list\n",
    "\n",
    "def get_test_data(data_dir):\n",
    "    img_path_list = []\n",
    "    \n",
    "    img_path_list.extend(glob(os.path.join(data_dir, '*.png')))\n",
    "    img_path_list.sort(key=lambda x:int(x.split('\\\\')[-1].split('.')[0]))\n",
    "\n",
    "    \n",
    "    return img_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76cf7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_path, all_label = get_train_data('aug')\n",
    "test_img_path = get_test_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d43c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aug\\\\20.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ad07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        img_path = self.img_path_list[index]\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        if self.train_mode:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52de5f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set 길이 :  4602\n",
      "vaildation set 길이 :  1534\n"
     ]
    }
   ],
   "source": [
    "train_len = int(len(all_img_path)*0.75)\n",
    "Vali_len = int(len(all_img_path)*0.25)\n",
    "\n",
    "train_img_path = all_img_path[:train_len]\n",
    "train_label = all_label[:train_len]\n",
    "\n",
    "vali_img_path = all_img_path[train_len:]\n",
    "vali_label = all_label[train_len:]\n",
    "\n",
    "print('train set 길이 : ', train_len)\n",
    "print('vaildation set 길이 : ', Vali_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8bf21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transform = transforms.Compose([\n",
    "                    transforms.ToPILImage(), \n",
    "                    transforms.Resize([CFG['img_size'], CFG['img_size']]),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) \n",
    "                    \n",
    "                    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize([CFG['img_size'], CFG['img_size']]),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc47097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_path, train_label, train_mode=True, transforms=train_transform) \n",
    "vali_dataset = CustomDataset(vali_img_path, vali_label, train_mode=True, transforms=test_transform)\n",
    "test_dataset = CustomDataset(vali_img_path, vali_label, train_mode=True, transforms=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13149f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 16,  tvt : 288 / 96 / 96\n"
     ]
    }
   ],
   "source": [
    "dataloaders, batch_num = {}, {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(train_dataset,\n",
    "                                              batch_size=CFG['batch'], shuffle=True,\n",
    "                                              num_workers=0)\n",
    "dataloaders['valid'] = torch.utils.data.DataLoader(vali_dataset,\n",
    "                                              batch_size=CFG['batch'], shuffle=False,\n",
    "                                              num_workers=0)\n",
    "dataloaders['test']  = torch.utils.data.DataLoader(vali_dataset,\n",
    "                                              batch_size=CFG['batch'], shuffle=False,\n",
    "                                              num_workers=0)\n",
    "batch_num['train'], batch_num['valid'], batch_num['test'] = len(dataloaders['train']), len(dataloaders['valid']), len(dataloaders['test'])\n",
    "print('batch_size : %d,  tvt : %d / %d / %d' % (CFG['batch'], batch_num['train'], batch_num['valid'], batch_num['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eaef366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "image_size = EfficientNet.get_image_size(CFG['model'])\n",
    "print(image_size)\n",
    "model = EfficientNet.from_pretrained(CFG['model'], num_classes=CFG['num_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e264871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                num_cnt += len(labels)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = float(running_loss / num_cnt)\n",
    "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                valid_loss.append(epoch_loss)\n",
    "                valid_acc.append(epoch_acc)\n",
    "            print('{} Loss: {:.2f} Acc: {:.1f}'.format(phase, epoch_loss, epoch_acc))\n",
    "           \n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_idx = epoch\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
    "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), 'president_model.pt')\n",
    "    print('model saved')\n",
    "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "461349d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=5.0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.ce = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23ca1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "\n",
    "\n",
    "optimizer_ft = optim.SGD(model.parameters(), \n",
    "                         lr = 5e-4,\n",
    "                         momentum=0.9,\n",
    "                         weight_decay=1e-4)\n",
    "\n",
    "lmbda = lambda epoch: 0.98739\n",
    "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61d77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=CFG['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef0d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            img = img.to(device)\n",
    "\n",
    "            pred_logit = model(img)\n",
    "            pred_logit = pred_logit.argmax(dim=1, keepdim=True).squeeze(1)\n",
    "\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred\n",
    "\n",
    "test_dataset = CustomDataset(test_img_path, None, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['batch'], shuffle=False, num_workers=0)\n",
    "\n",
    "# Inference\n",
    "preds = predict(model, test_loader, device)\n",
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = le.inverse_transform(preds)\n",
    "submission = pd.read_csv('test.csv')\n",
    "submission['label'] = answer\n",
    "\n",
    "label_split = df['label'].str.split(\"-\")\n",
    "submission[\"class\"] = label_split.str.get(0)\n",
    "submission[\"state\"] = label_split.str.get(1)\n",
    "\n",
    "submit = submission[['file_name','class','state','label']]\n",
    "\n",
    "submit.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "park",
   "language": "python",
   "name": "park"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
